{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad3f0d7",
   "metadata": {},
   "source": [
    "### Open this notebook in Colab and connect to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics==8.2.103 -q\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "# prevent ultralytics from tracking your activity\n",
    "!yolo settings sync=False\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b3876",
   "metadata": {},
   "source": [
    "#### 1. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load field dataset\n",
    "!curl -L \"https://app.roboflow.com/ds/u3XaPUMqaV?key=gYhHkujuQS\" > roboflow.zip; mkdir -p field_dataset && unzip roboflow.zip -d field_dataset; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to load dataset split into a dataframe\n",
    "def load_dataset_split(split_name):\n",
    "    \"\"\"\n",
    "    Load images and labels from a dataset split into a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        split_name: Name of the split ('train', 'valid', or 'test')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: image_path, label_path, filename, split\n",
    "    \"\"\"\n",
    "    split_dir = Path(split_name)\n",
    "    images_dir = split_dir / 'images'\n",
    "    labels_dir = split_dir / 'labels'\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = sorted(images_dir.glob('*.jpg'))\n",
    "    \n",
    "    data = []\n",
    "    for img_path in image_files:\n",
    "        # Get corresponding label file (same name but .txt extension)\n",
    "        label_filename = img_path.stem + '.txt'\n",
    "        label_path = labels_dir / label_filename\n",
    "        \n",
    "        data.append({\n",
    "            'image_path': str(img_path),\n",
    "            'label_path': str(label_path) if label_path.exists() else None,\n",
    "            'filename': img_path.name,\n",
    "            'split': split_name\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load train, validation, and test sets\n",
    "train_df = load_dataset_split('field_dataset/train')\n",
    "valid_df = load_dataset_split('field_dataset/valid')\n",
    "test_df = load_dataset_split('field_dataset/test')\n",
    "\n",
    "# Display summary\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(valid_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "print(f\"\\nTotal samples: {len(train_df) + len(valid_df) + len(test_df)}\")\n",
    "\n",
    "# Display first few rows of each dataframe\n",
    "print(\"\\n=== Train DataFrame (first 5 rows) ===\")\n",
    "print(train_df.head())\n",
    "print(\"\\n=== Validation DataFrame (first 5 rows) ===\")\n",
    "print(valid_df.head())\n",
    "print(\"\\n=== Test DataFrame (first 5 rows) ===\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4862ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define class names from data.yaml for field dataset\n",
    "CLASS_NAMES = ['pitch']\n",
    "NUM_KEYPOINTS = 32  # From data.yaml kpt_shape: [32, 3]\n",
    "\n",
    "def parse_yolo_label(label_path):\n",
    "    \"\"\"\n",
    "    Parse a YOLO format label file with keypoints.\n",
    "    \n",
    "    Args:\n",
    "        label_path: Path to the label file (.txt)\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries, each containing:\n",
    "        - class_id: int\n",
    "        - class_name: str\n",
    "        - x_center: float (normalized 0-1)\n",
    "        - y_center: float (normalized 0-1)\n",
    "        - width: float (normalized 0-1)\n",
    "        - height: float (normalized 0-1)\n",
    "        - keypoints: list of (x, y, visibility) tuples for each keypoint\n",
    "        - num_visible_keypoints: int (count of keypoints with visibility > 0)\n",
    "    \"\"\"\n",
    "    if label_path is None or not Path(label_path).exists():\n",
    "        return []\n",
    "    \n",
    "    annotations = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            # Format: class_id x_center y_center width height kpt1_x kpt1_y kpt1_vis ... kpt32_x kpt32_y kpt32_vis\n",
    "            # Expected: 5 + 32*3 = 101 values\n",
    "            if len(parts) >= 5:\n",
    "                class_id = int(parts[0])\n",
    "                x_center = float(parts[1])\n",
    "                y_center = float(parts[2])\n",
    "                width = float(parts[3])\n",
    "                height = float(parts[4])\n",
    "                \n",
    "                # Parse keypoints (remaining values after first 5)\n",
    "                keypoints = []\n",
    "                num_visible_keypoints = 0\n",
    "                for i in range(5, len(parts), 3):\n",
    "                    if i + 2 < len(parts):\n",
    "                        kpt_x = float(parts[i])\n",
    "                        kpt_y = float(parts[i + 1])\n",
    "                        kpt_vis = int(float(parts[i + 2]))  # visibility: 0=not labeled, 1=labeled but occluded, 2=labeled and visible\n",
    "                        keypoints.append((kpt_x, kpt_y, kpt_vis))\n",
    "                        if kpt_vis > 0:\n",
    "                            num_visible_keypoints += 1\n",
    "                \n",
    "                annotations.append({\n",
    "                    'class_id': class_id,\n",
    "                    'class_name': CLASS_NAMES[class_id],\n",
    "                    'x_center': x_center,\n",
    "                    'y_center': y_center,\n",
    "                    'width': width,\n",
    "                    'height': height,\n",
    "                    'keypoints': keypoints,\n",
    "                    'num_visible_keypoints': num_visible_keypoints\n",
    "                })\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def add_label_info(df):\n",
    "    \"\"\"\n",
    "    Add label information to the dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with label_path column\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with additional columns:\n",
    "        - annotations: list of all annotations in the image\n",
    "        - num_pitches: total number of pitch annotations\n",
    "        - avg_visible_keypoints: average number of visible keypoints per pitch\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Parse all labels\n",
    "    df['annotations'] = df['label_path'].apply(parse_yolo_label)\n",
    "    \n",
    "    # Count pitches (should be 1 per image for field dataset)\n",
    "    df['num_pitches'] = df['annotations'].apply(len)\n",
    "    \n",
    "    # Calculate average visible keypoints\n",
    "    df['avg_visible_keypoints'] = df['annotations'].apply(\n",
    "        lambda anns: np.mean([ann['num_visible_keypoints'] for ann in anns]) if anns else 0\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add label information to all dataframes\n",
    "print(\"Parsing labels...\")\n",
    "train_df = add_label_info(train_df)\n",
    "valid_df = add_label_info(valid_df)\n",
    "test_df = add_label_info(test_df)\n",
    "\n",
    "print(\"\\n=== Dataset Statistics ===\")\n",
    "for split_name, df in [('Train', train_df), ('Validation', valid_df), ('Test', test_df)]:\n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Total images: {len(df)}\")\n",
    "    print(f\"  Total pitches: {df['num_pitches'].sum()}\")\n",
    "    print(f\"  Avg pitches per image: {df['num_pitches'].mean():.2f}\")\n",
    "    print(f\"  Avg visible keypoints per pitch: {df['avg_visible_keypoints'].mean():.2f} / {NUM_KEYPOINTS}\")\n",
    "\n",
    "# Show updated dataframe with label info\n",
    "print(\"\\n=== Train DataFrame with Label Info (first 5 rows) ===\")\n",
    "print(train_df[['filename', 'num_pitches', 'avg_visible_keypoints']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# Define colors for pitch and keypoints\n",
    "PITCH_COLOR = 'lime'\n",
    "KEYPOINT_COLORS = {\n",
    "    0: 'red',      # Not labeled\n",
    "    1: 'yellow',   # Labeled but occluded\n",
    "    2: 'cyan'      # Labeled and visible\n",
    "}\n",
    "\n",
    "def visualize_sample(df, idx, figsize=(14, 10)):\n",
    "    \"\"\"\n",
    "    Visualize an image with its pitch bounding box and keypoints.\n",
    "    \"\"\"\n",
    "    row = df.iloc[idx]\n",
    "    \n",
    "    # Load image\n",
    "    img = Image.open(row['image_path'])\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Draw pitch annotations\n",
    "    for ann in row['annotations']:\n",
    "        # Convert from YOLO format to corner format for bounding box\n",
    "        x_center = ann['x_center'] * img_width\n",
    "        y_center = ann['y_center'] * img_height\n",
    "        width = ann['width'] * img_width\n",
    "        height = ann['height'] * img_height\n",
    "        \n",
    "        x_min = x_center - width / 2\n",
    "        y_min = y_center - height / 2\n",
    "        \n",
    "        # Draw bounding box\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), width, height,\n",
    "            linewidth=2, edgecolor=PITCH_COLOR, facecolor='none', linestyle='--'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Draw keypoints\n",
    "        for kpt_idx, (kpt_x, kpt_y, kpt_vis) in enumerate(ann['keypoints']):\n",
    "            if kpt_vis > 0:  # Only draw labeled keypoints\n",
    "                x_pixel = kpt_x * img_width\n",
    "                y_pixel = kpt_y * img_height\n",
    "                color = KEYPOINT_COLORS[kpt_vis]\n",
    "                \n",
    "                # Draw keypoint\n",
    "                ax.plot(x_pixel, y_pixel, 'o', color=color, markersize=8, \n",
    "                       markeredgecolor='white', markeredgewidth=1.5)\n",
    "                \n",
    "                # Optionally add keypoint number for first few keypoints\n",
    "                if kpt_idx < 10:  # Only label first 10 to avoid clutter\n",
    "                    ax.text(x_pixel + 5, y_pixel - 5, str(kpt_idx), \n",
    "                           fontsize=8, color='white', fontweight='bold',\n",
    "                           bbox=dict(boxstyle='round,pad=0.2', facecolor='black', alpha=0.5))\n",
    "        \n",
    "        # Add legend info\n",
    "        ax.text(\n",
    "            x_min, y_min - 10,\n",
    "            f\"Pitch ({ann['num_visible_keypoints']}/{NUM_KEYPOINTS} keypoints)\",\n",
    "            color=PITCH_COLOR,\n",
    "            fontsize=11,\n",
    "            fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.4', facecolor='black', alpha=0.7)\n",
    "        )\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color=PITCH_COLOR, linestyle='--', linewidth=2, label='Pitch BBox'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=KEYPOINT_COLORS[2], \n",
    "               markersize=8, label='Visible Keypoint', markeredgecolor='white'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=KEYPOINT_COLORS[1], \n",
    "               markersize=8, label='Occluded Keypoint', markeredgecolor='white')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "    \n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"{row['split']} - {row['filename']}\\nVisible Keypoints: {row['avg_visible_keypoints']:.0f}/{NUM_KEYPOINTS}\", \n",
    "                fontsize=12, pad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples\n",
    "print(\"=== Training Set Sample ===\")\n",
    "visualize_sample(train_df, 0)\n",
    "\n",
    "print(\"\\n=== Validation Set Sample ===\")\n",
    "visualize_sample(valid_df, 0)\n",
    "\n",
    "print(\"\\n=== Test Set Sample ===\")\n",
    "visualize_sample(test_df, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch keypoint analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Pitch count across splits\n",
    "ax = axes[0, 0]\n",
    "split_names = ['Train', 'Valid', 'Test']\n",
    "pitch_counts = [train_df['num_pitches'].sum(), valid_df['num_pitches'].sum(), test_df['num_pitches'].sum()]\n",
    "\n",
    "bars = ax.bar(split_names, pitch_counts, color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.7)\n",
    "ax.set_xlabel('Dataset Split')\n",
    "ax.set_ylabel('Number of Pitches')\n",
    "ax.set_title('Pitch Annotations Across Splits')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Visible keypoints distribution\n",
    "ax = axes[0, 1]\n",
    "ax.hist([train_df['avg_visible_keypoints'], valid_df['avg_visible_keypoints'], test_df['avg_visible_keypoints']], \n",
    "        label=['Train', 'Valid', 'Test'], bins=20, alpha=0.7)\n",
    "ax.set_xlabel('Number of Visible Keypoints')\n",
    "ax.set_ylabel('Number of Images')\n",
    "ax.set_title('Visible Keypoints per Pitch Distribution')\n",
    "ax.axvline(x=NUM_KEYPOINTS, color='red', linestyle='--', linewidth=2, label=f'Max ({NUM_KEYPOINTS})')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Bounding box size distribution (area)\n",
    "ax = axes[1, 0]\n",
    "for split_name, df in [('Train', train_df), ('Valid', valid_df), ('Test', test_df)]:\n",
    "    all_areas = []\n",
    "    for anns in df['annotations']:\n",
    "        for ann in anns:\n",
    "            area = ann['width'] * ann['height']  # Normalized area\n",
    "            all_areas.append(area)\n",
    "    if all_areas:\n",
    "        ax.hist(all_areas, bins=30, alpha=0.5, label=split_name)\n",
    "\n",
    "ax.set_xlabel('Pitch Bounding Box Area (normalized)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Pitch Bounding Box Size Distribution')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Keypoint visibility statistics\n",
    "ax = axes[1, 1]\n",
    "all_df = pd.concat([train_df, valid_df, test_df])\n",
    "\n",
    "# Calculate visibility statistics\n",
    "total_keypoints = 0\n",
    "visible_keypoints = 0\n",
    "occluded_keypoints = 0\n",
    "not_labeled_keypoints = 0\n",
    "\n",
    "for anns in all_df['annotations']:\n",
    "    for ann in anns:\n",
    "        for _, _, vis in ann['keypoints']:\n",
    "            total_keypoints += 1\n",
    "            if vis == 2:\n",
    "                visible_keypoints += 1\n",
    "            elif vis == 1:\n",
    "                occluded_keypoints += 1\n",
    "            else:\n",
    "                not_labeled_keypoints += 1\n",
    "\n",
    "visibility_data = [visible_keypoints, occluded_keypoints, not_labeled_keypoints]\n",
    "visibility_labels = [f'Visible\\n({visible_keypoints})', \n",
    "                     f'Occluded\\n({occluded_keypoints})', \n",
    "                     f'Not Labeled\\n({not_labeled_keypoints})']\n",
    "colors_list = [KEYPOINT_COLORS[2], KEYPOINT_COLORS[1], KEYPOINT_COLORS[0]]\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(visibility_data, labels=visibility_labels, autopct='%1.1f%%', \n",
    "                                    colors=colors_list, startangle=90)\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "ax.set_title('Overall Keypoint Visibility Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "print(f\"Total dataset size: {len(train_df) + len(valid_df) + len(test_df)} images\")\n",
    "print(f\"Total pitches: {all_df['num_pitches'].sum()}\")\n",
    "print(f\"Average visible keypoints per pitch: {all_df['avg_visible_keypoints'].mean():.2f} / {NUM_KEYPOINTS}\")\n",
    "print(f\"\\nKeypoint visibility breakdown:\")\n",
    "print(f\"  Visible (vis=2): {visible_keypoints} ({100*visible_keypoints/total_keypoints:.1f}%)\")\n",
    "print(f\"  Occluded (vis=1): {occluded_keypoints} ({100*occluded_keypoints/total_keypoints:.1f}%)\")\n",
    "print(f\"  Not labeled (vis=0): {not_labeled_keypoints} ({100*not_labeled_keypoints/total_keypoints:.1f}%)\")\n",
    "print(f\"  Total keypoints: {total_keypoints}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf2e970",
   "metadata": {},
   "source": [
    "#### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79bd9a1",
   "metadata": {},
   "source": [
    "##### 2.1. Random image augmentation (rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "def rotate_bbox_90(x_center, y_center, width, height, angle):\n",
    "    \"\"\"\n",
    "    Rotate bounding box coordinates for 90, 180, or 270 degree rotations.\n",
    "    \"\"\"\n",
    "    if angle == 90:\n",
    "        new_x_center = 1 - y_center\n",
    "        new_y_center = x_center\n",
    "        new_width = height\n",
    "        new_height = width\n",
    "    elif angle == 180:\n",
    "        new_x_center = 1 - x_center\n",
    "        new_y_center = 1 - y_center\n",
    "        new_width = width\n",
    "        new_height = height\n",
    "    elif angle == 270:\n",
    "        new_x_center = y_center\n",
    "        new_y_center = 1 - x_center\n",
    "        new_width = height\n",
    "        new_height = width\n",
    "    else:\n",
    "        raise ValueError(f\"Angle must be 90, 180, or 270, got {angle}\")\n",
    "    \n",
    "    return new_x_center, new_y_center, new_width, new_height\n",
    "\n",
    "def rotate_keypoint_90(x, y, angle):\n",
    "    \"\"\"\n",
    "    Rotate keypoint coordinates for 90, 180, or 270 degree rotations.\n",
    "    \"\"\"\n",
    "    if angle == 90:\n",
    "        new_x = 1 - y\n",
    "        new_y = x\n",
    "    elif angle == 180:\n",
    "        new_x = 1 - x\n",
    "        new_y = 1 - y\n",
    "    elif angle == 270:\n",
    "        new_x = y\n",
    "        new_y = 1 - x\n",
    "    else:\n",
    "        raise ValueError(f\"Angle must be 90, 180, or 270, got {angle}\")\n",
    "    \n",
    "    return new_x, new_y\n",
    "\n",
    "def rotate_image_90(image_path, angle):\n",
    "    \"\"\"\n",
    "    Rotate an image by 90, 180, or 270 degrees.\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    if angle == 90:\n",
    "        rotated = img.rotate(-90, expand=True)\n",
    "    elif angle == 180:\n",
    "        rotated = img.rotate(-180, expand=True)\n",
    "    elif angle == 270:\n",
    "        rotated = img.rotate(-270, expand=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Angle must be 90, 180, or 270, got {angle}\")\n",
    "    \n",
    "    return rotated\n",
    "\n",
    "def augment_dataset_with_rotations(df, split_name, augmentation_prob=0.5, rotation_angles=[90, 180, 270]):\n",
    "    \"\"\"\n",
    "    Apply random rotation augmentations to a dataset split with keypoint support.\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    \n",
    "    # Create augmented directories\n",
    "    aug_images_dir = Path(split_name) / 'images_augmented'\n",
    "    aug_labels_dir = Path(split_name) / 'labels_augmented'\n",
    "    aug_images_dir.mkdir(exist_ok=True)\n",
    "    aug_labels_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nAugmenting {split_name} set...\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if random.random() < augmentation_prob:\n",
    "            angle = random.choice(rotation_angles)\n",
    "            \n",
    "            original_img_path = row['image_path']\n",
    "            rotated_img = rotate_image_90(original_img_path, angle)\n",
    "            \n",
    "            base_filename = Path(row['filename']).stem\n",
    "            new_filename = f\"{base_filename}_rot{angle}.jpg\"\n",
    "            new_img_path = aug_images_dir / new_filename\n",
    "            new_label_path = aug_labels_dir / f\"{base_filename}_rot{angle}.txt\"\n",
    "            \n",
    "            rotated_img.save(new_img_path)\n",
    "            \n",
    "            rotated_annotations = []\n",
    "            with open(new_label_path, 'w') as f:\n",
    "                for ann in row['annotations']:\n",
    "                    # Rotate bounding box\n",
    "                    new_x, new_y, new_w, new_h = rotate_bbox_90(\n",
    "                        ann['x_center'], ann['y_center'],\n",
    "                        ann['width'], ann['height'],\n",
    "                        angle\n",
    "                    )\n",
    "                    \n",
    "                    # Rotate keypoints\n",
    "                    rotated_keypoints = []\n",
    "                    num_visible_keypoints = 0\n",
    "                    for kpt_x, kpt_y, kpt_vis in ann['keypoints']:\n",
    "                        if kpt_vis > 0:\n",
    "                            new_kpt_x, new_kpt_y = rotate_keypoint_90(kpt_x, kpt_y, angle)\n",
    "                            rotated_keypoints.append((new_kpt_x, new_kpt_y, kpt_vis))\n",
    "                            num_visible_keypoints += 1\n",
    "                        else:\n",
    "                            rotated_keypoints.append((kpt_x, kpt_y, kpt_vis))\n",
    "                    \n",
    "                    # Write to label file (format: class_id x y w h kpt1_x kpt1_y kpt1_vis ...)\n",
    "                    label_line = f\"{ann['class_id']} {new_x} {new_y} {new_w} {new_h}\"\n",
    "                    for kpt_x, kpt_y, kpt_vis in rotated_keypoints:\n",
    "                        label_line += f\" {kpt_x} {kpt_y} {kpt_vis}\"\n",
    "                    f.write(label_line + \"\\n\")\n",
    "                    \n",
    "                    rotated_annotations.append({\n",
    "                        'class_id': ann['class_id'],\n",
    "                        'class_name': ann['class_name'],\n",
    "                        'x_center': new_x,\n",
    "                        'y_center': new_y,\n",
    "                        'width': new_w,\n",
    "                        'height': new_h,\n",
    "                        'keypoints': rotated_keypoints,\n",
    "                        'num_visible_keypoints': num_visible_keypoints\n",
    "                    })\n",
    "            \n",
    "            augmented_data.append({\n",
    "                'image_path': str(new_img_path),\n",
    "                'label_path': str(new_label_path),\n",
    "                'filename': new_filename,\n",
    "                'split': split_name,\n",
    "                'annotations': rotated_annotations,\n",
    "                'augmented': True,\n",
    "                'augmentation_type': f'rotation_{angle}'\n",
    "            })\n",
    "            \n",
    "            if (idx + 1) % 50 == 0:\n",
    "                print(f\"  Processed {idx + 1}/{len(df)} images...\")\n",
    "    \n",
    "    print(f\"  Created {len(augmented_data)} augmented samples\")\n",
    "    \n",
    "    if augmented_data:\n",
    "        aug_df = pd.DataFrame(augmented_data)\n",
    "        aug_df['num_pitches'] = aug_df['annotations'].apply(len)\n",
    "        aug_df['avg_visible_keypoints'] = aug_df['annotations'].apply(\n",
    "            lambda anns: np.mean([ann['num_visible_keypoints'] for ann in anns]) if anns else 0\n",
    "        )\n",
    "        \n",
    "        df_copy = df.copy()\n",
    "        df_copy['augmented'] = False\n",
    "        df_copy['augmentation_type'] = 'original'\n",
    "        \n",
    "        combined_df = pd.concat([df_copy, aug_df], ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        df_copy = df.copy()\n",
    "        df_copy['augmented'] = False\n",
    "        df_copy['augmentation_type'] = 'original'\n",
    "        return df_copy\n",
    "\n",
    "print(\"Augmentation functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"APPLYING ROTATION AUGMENTATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply augmentation to training set (50% of images)\n",
    "train_df_augmented = augment_dataset_with_rotations(\n",
    "    train_df, \n",
    "    'field_dataset/train', \n",
    "    augmentation_prob=0.5,\n",
    "    rotation_angles=[90, 180, 270]\n",
    ")\n",
    "\n",
    "# Apply augmentation to validation set (30% of images)\n",
    "valid_df_augmented = augment_dataset_with_rotations(\n",
    "    valid_df, \n",
    "    'field_dataset/valid', \n",
    "    augmentation_prob=0.3,\n",
    "    rotation_angles=[90, 180, 270]\n",
    ")\n",
    "\n",
    "# Apply augmentation to test set (30% of images)\n",
    "test_df_augmented = augment_dataset_with_rotations(\n",
    "    test_df, \n",
    "    'field_dataset/test', \n",
    "    augmentation_prob=0.3,\n",
    "    rotation_angles=[90, 180, 270]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"AUGMENTATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display updated statistics\n",
    "print(\"\\n=== UPDATED DATASET STATISTICS (with augmentation) ===\")\n",
    "for split_name, df in [('Train', train_df_augmented), ('Validation', valid_df_augmented), ('Test', test_df_augmented)]:\n",
    "    original_count = len(df[df['augmented'] == False])\n",
    "    augmented_count = len(df[df['augmented'] == True])\n",
    "    \n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Original images: {original_count}\")\n",
    "    print(f\"  Augmented images: {augmented_count}\")\n",
    "    print(f\"  Total images: {len(df)}\")\n",
    "    print(f\"  Total pitches: {df['num_pitches'].sum()}\")\n",
    "    print(f\"  Avg pitches per image: {df['num_pitches'].mean():.2f}\")\n",
    "    print(f\"  Avg visible keypoints per pitch: {df['avg_visible_keypoints'].mean():.2f} / {NUM_KEYPOINTS}\")\n",
    "    \n",
    "    # Show augmentation type distribution\n",
    "    if augmented_count > 0:\n",
    "        print(f\"  Augmentation types:\")\n",
    "        for aug_type in df[df['augmented'] == True]['augmentation_type'].value_counts().items():\n",
    "            print(f\"    {aug_type[0]}: {aug_type[1]} images\")\n",
    "\n",
    "# Update the original dataframes with augmented versions\n",
    "train_df = train_df_augmented\n",
    "valid_df = valid_df_augmented\n",
    "test_df = test_df_augmented\n",
    "\n",
    "print(\"\\n✓ DataFrames updated with augmented data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_pitch_annotation(ax, ann, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Helper function to draw pitch bounding box and keypoints on an axis.\n",
    "    \"\"\"\n",
    "    # Draw bounding box\n",
    "    x_center = ann['x_center'] * img_width\n",
    "    y_center = ann['y_center'] * img_height\n",
    "    width = ann['width'] * img_width\n",
    "    height = ann['height'] * img_height\n",
    "    x_min = x_center - width / 2\n",
    "    y_min = y_center - height / 2\n",
    "    \n",
    "    rect = patches.Rectangle(\n",
    "        (x_min, y_min), width, height,\n",
    "        linewidth=2, edgecolor=PITCH_COLOR, facecolor='none', linestyle='--'\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    for kpt_x, kpt_y, kpt_vis in ann['keypoints']:\n",
    "        if kpt_vis > 0:  # Only draw labeled keypoints\n",
    "            x_pixel = kpt_x * img_width\n",
    "            y_pixel = kpt_y * img_height\n",
    "            color = KEYPOINT_COLORS[kpt_vis]\n",
    "            \n",
    "            ax.plot(x_pixel, y_pixel, 'o', color=color, markersize=6, \n",
    "                   markeredgecolor='white', markeredgewidth=1.2)\n",
    "\n",
    "def visualize_original_vs_augmented(df, original_idx):\n",
    "    \"\"\"\n",
    "    Visualize an original pitch image and its augmented versions side by side.\n",
    "    \"\"\"\n",
    "    # Get original image\n",
    "    original_row = df[(df['augmented'] == False)].iloc[original_idx]\n",
    "    original_filename_stem = Path(original_row['filename']).stem\n",
    "    \n",
    "    # Find augmented versions\n",
    "    augmented_rows = df[\n",
    "        (df['augmented'] == True) & \n",
    "        (df['filename'].str.contains(original_filename_stem))\n",
    "    ]\n",
    "    \n",
    "    # Create subplots\n",
    "    num_images = 1 + len(augmented_rows)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(6 * num_images, 6))\n",
    "    \n",
    "    if num_images == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Plot original\n",
    "    img = Image.open(original_row['image_path'])\n",
    "    img_width, img_height = img.size\n",
    "    axes[0].imshow(img)\n",
    "    \n",
    "    for ann in original_row['annotations']:\n",
    "        draw_pitch_annotation(axes[0], ann, img_width, img_height)\n",
    "    \n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title(f\"Original\\n{original_row['filename'][:30]}...\\n{original_row['avg_visible_keypoints']:.0f}/{NUM_KEYPOINTS} kpts\", \n",
    "                     fontsize=10)\n",
    "    \n",
    "    # Plot augmented versions\n",
    "    for idx, (_, aug_row) in enumerate(augmented_rows.iterrows(), start=1):\n",
    "        img = Image.open(aug_row['image_path'])\n",
    "        img_width, img_height = img.size\n",
    "        axes[idx].imshow(img)\n",
    "        \n",
    "        for ann in aug_row['annotations']:\n",
    "            draw_pitch_annotation(axes[idx], ann, img_width, img_height)\n",
    "        \n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f\"{aug_row['augmentation_type']}\\n{aug_row['filename'][:30]}...\\n{aug_row['avg_visible_keypoints']:.0f}/{NUM_KEYPOINTS} kpts\", \n",
    "                           fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VISUALIZING ORIGINAL VS AUGMENTED IMAGES\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nShowing original pitch images with their rotated augmentations...\")\n",
    "print(\"(Lime=pitch bbox, Cyan=visible keypoint, Yellow=occluded keypoint)\\n\")\n",
    "\n",
    "# Visualize a few examples from training set\n",
    "for i in range(min(3, len(train_df[train_df['augmented'] == False]))):\n",
    "    print(f\"\\n--- Training Example {i+1} ---\")\n",
    "    visualize_original_vs_augmented(train_df, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save augmented dataframes to CSV for future reference\n",
    "print(\"=\" * 70)\n",
    "print(\"SAVING AUGMENTED DATASET INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "train_df.to_csv('train_augmented.csv', index=False)\n",
    "valid_df.to_csv('valid_augmented.csv', index=False)\n",
    "test_df.to_csv('test_augmented.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Saved augmented dataset info to CSV files:\")\n",
    "print(\"  - field_dataset/train_augmented.csv\")\n",
    "print(\"  - field_dataset/valid_augmented.csv\")\n",
    "print(\"  - field_dataset/test_augmented.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CQC24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
