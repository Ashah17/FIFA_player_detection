{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad3f0d7",
   "metadata": {},
   "source": [
    "### Open this notebook in Colab and connect to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics==8.2.103 -q\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "# prevent ultralytics from tracking your activity\n",
    "!yolo settings sync=False\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b3876",
   "metadata": {},
   "source": [
    "#### 1. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5265b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load player dataset\n",
    "!curl -L \"https://app.roboflow.com/ds/igCstoe8Mj?key=yu5jsVVWYs\" > roboflow.zip; mkdir -p player_dataset && unzip roboflow.zip -d player_dataset; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to load dataset split into a dataframe\n",
    "def load_dataset_split(split_name):\n",
    "    \"\"\"\n",
    "    Load images and labels from a dataset split into a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        split_name: Name of the split ('train', 'valid', or 'test')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: image_path, label_path, filename, split\n",
    "    \"\"\"\n",
    "    split_dir = Path(split_name)\n",
    "    images_dir = split_dir / 'images'\n",
    "    labels_dir = split_dir / 'labels'\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = sorted(images_dir.glob('*.jpg'))\n",
    "    \n",
    "    data = []\n",
    "    for img_path in image_files:\n",
    "        # Get corresponding label file (same name but .txt extension)\n",
    "        label_filename = img_path.stem + '.txt'\n",
    "        label_path = labels_dir / label_filename\n",
    "        \n",
    "        data.append({\n",
    "            'image_path': str(img_path),\n",
    "            'label_path': str(label_path) if label_path.exists() else None,\n",
    "            'filename': img_path.name,\n",
    "            'split': split_name\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load train, validation, and test sets\n",
    "train_df = load_dataset_split('player_dataset/train')\n",
    "valid_df = load_dataset_split('player_dataset/valid')\n",
    "test_df = load_dataset_split('player_dataset/test')\n",
    "\n",
    "# Display summary\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(valid_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "print(f\"\\nTotal samples: {len(train_df) + len(valid_df) + len(test_df)}\")\n",
    "\n",
    "# Display first few rows of each dataframe\n",
    "print(\"\\n=== Train DataFrame (first 5 rows) ===\")\n",
    "print(train_df.head())\n",
    "print(\"\\n=== Validation DataFrame (first 5 rows) ===\")\n",
    "print(valid_df.head())\n",
    "print(\"\\n=== Test DataFrame (first 5 rows) ===\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4862ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define class names from data.yaml\n",
    "CLASS_NAMES = ['ball', 'goalkeeper', 'player', 'referee']\n",
    "\n",
    "def parse_yolo_label(label_path):\n",
    "    \"\"\"\n",
    "    Parse a YOLO format label file.\n",
    "    \n",
    "    Args:\n",
    "        label_path: Path to the label file (.txt)\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries, each containing:\n",
    "        - class_id: int\n",
    "        - class_name: str\n",
    "        - x_center: float (normalized 0-1)\n",
    "        - y_center: float (normalized 0-1)\n",
    "        - width: float (normalized 0-1)\n",
    "        - height: float (normalized 0-1)\n",
    "    \"\"\"\n",
    "    if label_path is None or not Path(label_path).exists():\n",
    "        return []\n",
    "    \n",
    "    annotations = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                class_id = int(parts[0])\n",
    "                x_center = float(parts[1])\n",
    "                y_center = float(parts[2])\n",
    "                width = float(parts[3])\n",
    "                height = float(parts[4])\n",
    "                \n",
    "                annotations.append({\n",
    "                    'class_id': class_id,\n",
    "                    'class_name': CLASS_NAMES[class_id],\n",
    "                    'x_center': x_center,\n",
    "                    'y_center': y_center,\n",
    "                    'width': width,\n",
    "                    'height': height\n",
    "                })\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def add_label_info(df):\n",
    "    \"\"\"\n",
    "    Add label information to the dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with label_path column\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with additional columns:\n",
    "        - annotations: list of all annotations in the image\n",
    "        - num_objects: total number of objects\n",
    "        - num_balls, num_goalkeepers, num_players, num_referees: count per class\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Parse all labels\n",
    "    df['annotations'] = df['label_path'].apply(parse_yolo_label)\n",
    "    \n",
    "    # Count total objects\n",
    "    df['num_objects'] = df['annotations'].apply(len)\n",
    "    \n",
    "    # Count per class\n",
    "    for class_id, class_name in enumerate(CLASS_NAMES):\n",
    "        df[f'num_{class_name}s'] = df['annotations'].apply(\n",
    "            lambda anns: sum(1 for ann in anns if ann['class_id'] == class_id)\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add label information to all dataframes\n",
    "print(\"Parsing labels...\")\n",
    "train_df = add_label_info(train_df)\n",
    "valid_df = add_label_info(valid_df)\n",
    "test_df = add_label_info(test_df)\n",
    "\n",
    "print(\"\\n=== Dataset Statistics ===\")\n",
    "for split_name, df in [('Train', train_df), ('Validation', valid_df), ('Test', test_df)]:\n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Total images: {len(df)}\")\n",
    "    print(f\"  Total objects: {df['num_objects'].sum()}\")\n",
    "    print(f\"  Avg objects per image: {df['num_objects'].mean():.2f}\")\n",
    "    print(f\"  Objects per class:\")\n",
    "    for class_name in CLASS_NAMES:\n",
    "        total = df[f'num_{class_name}s'].sum()\n",
    "        print(f\"    {class_name}: {total}\")\n",
    "\n",
    "# Show updated dataframe with label info\n",
    "print(\"\\n=== Train DataFrame with Label Info (first 5 rows) ===\")\n",
    "print(train_df[['filename', 'num_objects', 'num_balls', 'num_goalkeepers', 'num_players', 'num_referees']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# Define colors for each class\n",
    "CLASS_COLORS = {\n",
    "    'ball': 'red',\n",
    "    'goalkeeper': 'yellow',\n",
    "    'player': 'blue',\n",
    "    'referee': 'green'\n",
    "}\n",
    "\n",
    "def visualize_sample(df, idx, figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Visualize an image with its bounding boxes.\n",
    "    \"\"\"\n",
    "    row = df.iloc[idx]\n",
    "    \n",
    "    # Load image\n",
    "    img = Image.open(row['image_path'])\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    for ann in row['annotations']:\n",
    "        # Convert from YOLO format to corner format\n",
    "        x_center = ann['x_center'] * img_width\n",
    "        y_center = ann['y_center'] * img_height\n",
    "        width = ann['width'] * img_width\n",
    "        height = ann['height'] * img_height\n",
    "        \n",
    "        x_min = x_center - width / 2\n",
    "        y_min = y_center - height / 2\n",
    "        \n",
    "        color = CLASS_COLORS[ann['class_name']]\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), width, height,\n",
    "            linewidth=2, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        ax.text(\n",
    "            x_min, y_min - 5,\n",
    "            ann['class_name'],\n",
    "            color=color,\n",
    "            fontsize=10,\n",
    "            fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7)\n",
    "        )\n",
    "    \n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"{row['split']} - {row['filename']}\\nObjects: {row['num_objects']}\", fontsize=12, pad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples\n",
    "print(\"=== Training Set Sample ===\")\n",
    "visualize_sample(train_df, 0)\n",
    "\n",
    "print(\"\\n=== Validation Set Sample ===\")\n",
    "visualize_sample(valid_df, 0)\n",
    "\n",
    "print(\"\\n=== Test Set Sample ===\")\n",
    "visualize_sample(test_df, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Class distribution across splits\n",
    "class_counts = {}\n",
    "for split_name, df in [('Train', train_df), ('Valid', valid_df), ('Test', test_df)]:\n",
    "    class_counts[split_name] = [df[f'num_{cls}s'].sum() for cls in CLASS_NAMES]\n",
    "\n",
    "x = np.arange(len(CLASS_NAMES))\n",
    "width = 0.25\n",
    "\n",
    "ax = axes[0, 0]\n",
    "for i, (split_name, counts) in enumerate(class_counts.items()):\n",
    "    ax.bar(x + i * width, counts, width, label=split_name)\n",
    "\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Class Distribution Across Splits')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(CLASS_NAMES)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Objects per image distribution\n",
    "ax = axes[0, 1]\n",
    "ax.hist([train_df['num_objects'], valid_df['num_objects'], test_df['num_objects']], \n",
    "        label=['Train', 'Valid', 'Test'], bins=20, alpha=0.7)\n",
    "ax.set_xlabel('Number of Objects')\n",
    "ax.set_ylabel('Number of Images')\n",
    "ax.set_title('Objects per Image Distribution')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Bounding box size distribution (area)\n",
    "ax = axes[1, 0]\n",
    "for split_name, df in [('Train', train_df), ('Valid', valid_df), ('Test', test_df)]:\n",
    "    all_areas = []\n",
    "    for anns in df['annotations']:\n",
    "        for ann in anns:\n",
    "            area = ann['width'] * ann['height']  # Normalized area\n",
    "            all_areas.append(area)\n",
    "    ax.hist(all_areas, bins=50, alpha=0.5, label=split_name)\n",
    "\n",
    "ax.set_xlabel('Bounding Box Area (normalized)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Bounding Box Size Distribution')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Class distribution pie chart (combined)\n",
    "ax = axes[1, 1]\n",
    "all_df = pd.concat([train_df, valid_df, test_df])\n",
    "total_per_class = [all_df[f'num_{cls}s'].sum() for cls in CLASS_NAMES]\n",
    "colors_list = [CLASS_COLORS[cls] for cls in CLASS_NAMES]\n",
    "\n",
    "ax.pie(total_per_class, labels=CLASS_NAMES, autopct='%1.1f%%', \n",
    "       colors=colors_list, startangle=90)\n",
    "ax.set_title('Overall Class Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "print(f\"Total dataset size: {len(train_df) + len(valid_df) + len(test_df)} images\")\n",
    "print(f\"Total objects: {sum(total_per_class)}\")\n",
    "print(f\"\\nClass imbalance ratio:\")\n",
    "max_count = max(total_per_class)\n",
    "for cls, count in zip(CLASS_NAMES, total_per_class):\n",
    "    ratio = count / max_count\n",
    "    print(f\"  {cls}: {count} ({ratio:.2%} of most common class)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf2e970",
   "metadata": {},
   "source": [
    "#### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79bd9a1",
   "metadata": {},
   "source": [
    "##### 2.1. Random image augmentation (rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "def rotate_bbox_90(x_center, y_center, width, height, angle):\n",
    "    \"\"\"\n",
    "    Rotate bounding box coordinates for 90, 180, or 270 degree rotations.\n",
    "    \"\"\"\n",
    "    if angle == 90:\n",
    "        new_x_center = 1 - y_center\n",
    "        new_y_center = x_center\n",
    "        new_width = height\n",
    "        new_height = width\n",
    "    elif angle == 180:\n",
    "        new_x_center = 1 - x_center\n",
    "        new_y_center = 1 - y_center\n",
    "        new_width = width\n",
    "        new_height = height\n",
    "    elif angle == 270:\n",
    "        new_x_center = y_center\n",
    "        new_y_center = 1 - x_center\n",
    "        new_width = height\n",
    "        new_height = width\n",
    "    else:\n",
    "        raise ValueError(f\"Angle must be 90, 180, or 270, got {angle}\")\n",
    "    \n",
    "    return new_x_center, new_y_center, new_width, new_height\n",
    "\n",
    "def rotate_image_90(image_path, angle):\n",
    "    \"\"\"\n",
    "    Rotate an image by 90, 180, or 270 degrees.\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    if angle == 90:\n",
    "        rotated = img.rotate(-90, expand=True)\n",
    "    elif angle == 180:\n",
    "        rotated = img.rotate(-180, expand=True)\n",
    "    elif angle == 270:\n",
    "        rotated = img.rotate(-270, expand=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Angle must be 90, 180, or 270, got {angle}\")\n",
    "    \n",
    "    return rotated\n",
    "\n",
    "def augment_dataset_with_rotations(df, split_name, augmentation_prob=0.5, rotation_angles=[90, 180, 270]):\n",
    "    \"\"\"\n",
    "    Apply random rotation augmentations to a dataset split.\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    \n",
    "    # Create augmented directories\n",
    "    aug_images_dir = 'player_dataset' / Path(split_name) / 'images_augmented'\n",
    "    aug_labels_dir = 'player_dataset' / Path(split_name) / 'labels_augmented'\n",
    "    aug_images_dir.mkdir(exist_ok=True)\n",
    "    aug_labels_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nAugmenting {split_name} set...\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if random.random() < augmentation_prob:\n",
    "            angle = random.choice(rotation_angles)\n",
    "            \n",
    "            original_img_path = row['image_path']\n",
    "            rotated_img = rotate_image_90(original_img_path, angle)\n",
    "            \n",
    "            base_filename = Path(row['filename']).stem\n",
    "            new_filename = f\"{base_filename}_rot{angle}.jpg\"\n",
    "            new_img_path = aug_images_dir / new_filename\n",
    "            new_label_path = aug_labels_dir / f\"{base_filename}_rot{angle}.txt\"\n",
    "            \n",
    "            rotated_img.save(new_img_path)\n",
    "            \n",
    "            rotated_annotations = []\n",
    "            with open(new_label_path, 'w') as f:\n",
    "                for ann in row['annotations']:\n",
    "                    new_x, new_y, new_w, new_h = rotate_bbox_90(\n",
    "                        ann['x_center'], ann['y_center'],\n",
    "                        ann['width'], ann['height'],\n",
    "                        angle\n",
    "                    )\n",
    "                    \n",
    "                    f.write(f\"{ann['class_id']} {new_x} {new_y} {new_w} {new_h}\\n\")\n",
    "                    \n",
    "                    rotated_annotations.append({\n",
    "                        'class_id': ann['class_id'],\n",
    "                        'class_name': ann['class_name'],\n",
    "                        'x_center': new_x,\n",
    "                        'y_center': new_y,\n",
    "                        'width': new_w,\n",
    "                        'height': new_h\n",
    "                    })\n",
    "            \n",
    "            augmented_data.append({\n",
    "                'image_path': str(new_img_path),\n",
    "                'label_path': str(new_label_path),\n",
    "                'filename': new_filename,\n",
    "                'split': split_name,\n",
    "                'annotations': rotated_annotations,\n",
    "                'augmented': True,\n",
    "                'augmentation_type': f'rotation_{angle}'\n",
    "            })\n",
    "            \n",
    "            if (idx + 1) % 50 == 0:\n",
    "                print(f\"  Processed {idx + 1}/{len(df)} images...\")\n",
    "    \n",
    "    print(f\"  Created {len(augmented_data)} augmented samples\")\n",
    "    \n",
    "    if augmented_data:\n",
    "        aug_df = pd.DataFrame(augmented_data)\n",
    "        aug_df['num_objects'] = aug_df['annotations'].apply(len)\n",
    "        for class_id, class_name in enumerate(CLASS_NAMES):\n",
    "            aug_df[f'num_{class_name}s'] = aug_df['annotations'].apply(\n",
    "                lambda anns: sum(1 for ann in anns if ann['class_id'] == class_id)\n",
    "            )\n",
    "        \n",
    "        df_copy = df.copy()\n",
    "        df_copy['augmented'] = False\n",
    "        df_copy['augmentation_type'] = 'original'\n",
    "        \n",
    "        combined_df = pd.concat([df_copy, aug_df], ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        df_copy = df.copy()\n",
    "        df_copy['augmented'] = False\n",
    "        df_copy['augmentation_type'] = 'original'\n",
    "        return df_copy\n",
    "\n",
    "print(\"Augmentation functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"APPLYING ROTATION AUGMENTATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply augmentation to training set (50% of images)\n",
    "train_df_augmented = augment_dataset_with_rotations(\n",
    "    train_df, \n",
    "    'train', \n",
    "    augmentation_prob=0.5,\n",
    "    rotation_angles=[90, 180, 270]\n",
    ")\n",
    "\n",
    "# Apply augmentation to validation set (30% of images)\n",
    "valid_df_augmented = augment_dataset_with_rotations(\n",
    "    valid_df, \n",
    "    'valid', \n",
    "    augmentation_prob=0.3,\n",
    "    rotation_angles=[90, 180, 270]\n",
    ")\n",
    "\n",
    "# Apply augmentation to test set (30% of images)\n",
    "test_df_augmented = augment_dataset_with_rotations(\n",
    "    test_df, \n",
    "    'test', \n",
    "    augmentation_prob=0.3,\n",
    "    rotation_angles=[90, 180, 270]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"AUGMENTATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display updated statistics\n",
    "print(\"\\n=== UPDATED DATASET STATISTICS (with augmentation) ===\")\n",
    "for split_name, df in [('Train', train_df_augmented), ('Validation', valid_df_augmented), ('Test', test_df_augmented)]:\n",
    "    original_count = len(df[df['augmented'] == False])\n",
    "    augmented_count = len(df[df['augmented'] == True])\n",
    "    \n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Original images: {original_count}\")\n",
    "    print(f\"  Augmented images: {augmented_count}\")\n",
    "    print(f\"  Total images: {len(df)}\")\n",
    "    print(f\"  Total objects: {df['num_objects'].sum()}\")\n",
    "    print(f\"  Avg objects per image: {df['num_objects'].mean():.2f}\")\n",
    "    print(f\"  Objects per class:\")\n",
    "    for class_name in CLASS_NAMES:\n",
    "        total = df[f'num_{class_name}s'].sum()\n",
    "        print(f\"    {class_name}: {total}\")\n",
    "    \n",
    "    # Show augmentation type distribution\n",
    "    if augmented_count > 0:\n",
    "        print(f\"  Augmentation types:\")\n",
    "        for aug_type in df[df['augmented'] == True]['augmentation_type'].value_counts().items():\n",
    "            print(f\"    {aug_type[0]}: {aug_type[1]} images\")\n",
    "\n",
    "# Update the original dataframes with augmented versions\n",
    "train_df = train_df_augmented\n",
    "valid_df = valid_df_augmented\n",
    "test_df = test_df_augmented\n",
    "\n",
    "print(\"\\n✓ DataFrames updated with augmented data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Define colors for each class\n",
    "CLASS_COLORS = {\n",
    "    'ball': 'red',\n",
    "    'goalkeeper': 'yellow',\n",
    "    'player': 'blue',\n",
    "    'referee': 'green'\n",
    "}\n",
    "\n",
    "def visualize_original_vs_augmented(df, original_idx):\n",
    "    \"\"\"\n",
    "    Visualize an original image and its augmented versions side by side.\n",
    "    \"\"\"\n",
    "    # Get original image\n",
    "    original_row = df[(df['augmented'] == False)].iloc[original_idx]\n",
    "    original_filename_stem = Path(original_row['filename']).stem\n",
    "    \n",
    "    # Find augmented versions\n",
    "    augmented_rows = df[\n",
    "        (df['augmented'] == True) & \n",
    "        (df['filename'].str.contains(original_filename_stem))\n",
    "    ]\n",
    "    \n",
    "    # Create subplots\n",
    "    num_images = 1 + len(augmented_rows)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(6 * num_images, 6))\n",
    "    \n",
    "    if num_images == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Plot original\n",
    "    img = Image.open(original_row['image_path'])\n",
    "    img_width, img_height = img.size\n",
    "    axes[0].imshow(img)\n",
    "    \n",
    "    for ann in original_row['annotations']:\n",
    "        x_center = ann['x_center'] * img_width\n",
    "        y_center = ann['y_center'] * img_height\n",
    "        width = ann['width'] * img_width\n",
    "        height = ann['height'] * img_height\n",
    "        x_min = x_center - width / 2\n",
    "        y_min = y_center - height / 2\n",
    "        \n",
    "        color = CLASS_COLORS[ann['class_name']]\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), width, height,\n",
    "            linewidth=2, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        axes[0].add_patch(rect)\n",
    "    \n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title(f\"Original\\n{original_row['filename'][:30]}...\", fontsize=10)\n",
    "    \n",
    "    # Plot augmented versions\n",
    "    for idx, (_, aug_row) in enumerate(augmented_rows.iterrows(), start=1):\n",
    "        img = Image.open(aug_row['image_path'])\n",
    "        img_width, img_height = img.size\n",
    "        axes[idx].imshow(img)\n",
    "        \n",
    "        for ann in aug_row['annotations']:\n",
    "            x_center = ann['x_center'] * img_width\n",
    "            y_center = ann['y_center'] * img_height\n",
    "            width = ann['width'] * img_width\n",
    "            height = ann['height'] * img_height\n",
    "            x_min = x_center - width / 2\n",
    "            y_min = y_center - height / 2\n",
    "            \n",
    "            color = CLASS_COLORS[ann['class_name']]\n",
    "            rect = patches.Rectangle(\n",
    "                (x_min, y_min), width, height,\n",
    "                linewidth=2, edgecolor=color, facecolor='none'\n",
    "            )\n",
    "            axes[idx].add_patch(rect)\n",
    "        \n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f\"{aug_row['augmentation_type']}\\n{aug_row['filename'][:30]}...\", fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VISUALIZING ORIGINAL VS AUGMENTED IMAGES\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nShowing original images with their rotated augmentations...\")\n",
    "print(\"(Colors: Red=ball, Yellow=goalkeeper, Blue=player, Green=referee)\\n\")\n",
    "\n",
    "# Visualize a few examples from training set\n",
    "for i in range(min(3, len(train_df[train_df['augmented'] == False]))):\n",
    "    print(f\"\\n--- Training Example {i+1} ---\")\n",
    "    visualize_original_vs_augmented(train_df, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save augmented dataframes to CSV for future reference\n",
    "print(\"=\" * 70)\n",
    "print(\"SAVING AUGMENTED DATASET INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "train_df.to_csv('train_augmented.csv', index=False)\n",
    "valid_df.to_csv('valid_augmented.csv', index=False)\n",
    "test_df.to_csv('test_augmented.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Saved augmented dataset info to CSV files:\")\n",
    "print(\"  - player_dataset/train_augmented.csv\")\n",
    "print(\"  - player_dataset/valid_augmented.csv\")\n",
    "print(\"  - player_dataset/test_augmented.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CQC24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
