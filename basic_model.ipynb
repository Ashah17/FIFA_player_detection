{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.13.7 torch-2.9.1 CPU (Apple M4)\n",
      "Setup complete âœ… (10 CPUs, 16.0 GB RAM, 132.2/460.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics==8.2.103 \"opencv-python-headless<4.9\" easyocr scikit-learn pandas numpy -q\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "# Import libraries\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "import easyocr\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Prevent ultralytics from tracking\n",
    "!yolo settings sync=False\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generic Helper Functions ---\n",
    "def load_dataset_split(base_dir, split_name):\n",
    "    \"\"\"Loads a dataset split into a dataframe.\"\"\"\n",
    "    split_dir = Path(base_dir) / split_name\n",
    "    images_dir = split_dir / 'images_orig'\n",
    "    labels_dir = split_dir / 'labels_orig'\n",
    "\n",
    "    # --- NEW CHECK ---\n",
    "    if not images_dir.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Error: The directory '{images_dir}' does not exist. \"\n",
    "            \"Please check that your dataset downloaded and unzipped correctly. \"\n",
    "            f\"Expected structure: {base_dir}/{split_name}/images\"\n",
    "        )\n",
    "    # --- END NEW CHECK ---\n",
    "    \n",
    "    image_files = sorted(images_dir.glob('*.jpg'))\n",
    "\n",
    "    # --- NEW CHECK ---\n",
    "    if not image_files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Error: No '.jpg' files were found in '{images_dir}'. \"\n",
    "            \"The directory is empty or the download may have failed.\"\n",
    "        )\n",
    "    # --- END NEW CHECK ---\n",
    "    \n",
    "    data = []\n",
    "    for img_path in image_files:\n",
    "        label_filename = img_path.stem + '.txt'\n",
    "        label_path = labels_dir / label_filename\n",
    "        data.append({\n",
    "            'image_path': str(img_path),\n",
    "            'label_path': str(label_path) if label_path.exists() else None,\n",
    "            'filename': img_path.name,\n",
    "            'split': split_name\n",
    "        })\n",
    "    \n",
    "    print(f\"  Loaded {len(data)} images from {images_dir}\") # Added for visibility\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# --- Rotation/Augmentation Functions ---\n",
    "\n",
    "def rotate_bbox_90(x_center, y_center, width, height, angle):\n",
    "    \"\"\"Rotate bounding box coordinates for 90, 180, or 270 degree rotations.\"\"\"\n",
    "    if angle == 90:\n",
    "        return 1 - y_center, x_center, height, width\n",
    "    elif angle == 180:\n",
    "        return 1 - x_center, 1 - y_center, width, height\n",
    "    elif angle == 270:\n",
    "        return y_center, 1 - x_center, height, width\n",
    "    raise ValueError(\"Angle must be 90, 180, or 270\")\n",
    "\n",
    "def rotate_keypoint_90(x, y, angle):\n",
    "    \"\"\"Rotate keypoint coordinates for 90, 180, or 270 degree rotations.\"\"\"\n",
    "    if angle == 90:\n",
    "        return 1 - y, x\n",
    "    elif angle == 180:\n",
    "        return 1 - x, 1 - y\n",
    "    elif angle == 270:\n",
    "        return y, 1 - x\n",
    "    raise ValueError(\"Angle must be 90, 180, or 270\")\n",
    "\n",
    "def rotate_image_90(image_path, angle):\n",
    "    \"\"\"Rotate an image by 90, 180, or 270 degrees.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    if angle == 90:\n",
    "        return img.rotate(-90, expand=True)\n",
    "    elif angle == 180:\n",
    "        return img.rotate(-180, expand=True)\n",
    "    elif angle == 270:\n",
    "        return img.rotate(-270, expand=True)\n",
    "    raise ValueError(\"Angle must be 90, 180, or 270\")\n",
    "\n",
    "# --- Field Dataset (Keypoints) Functions ---\n",
    "FIELD_CLASS_NAMES = ['pitch']\n",
    "NUM_KEYPOINTS = 32\n",
    "\n",
    "def parse_field_label(label_path):\n",
    "    \"\"\"Parse a YOLO format label file with keypoints.\"\"\"\n",
    "    if label_path is None or not Path(label_path).exists():\n",
    "        return []\n",
    "    annotations = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id, x_c, y_c, w, h = int(parts[0]), float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
    "                keypoints = []\n",
    "                num_visible_keypoints = 0\n",
    "                for i in range(5, len(parts), 3):\n",
    "                    if i + 2 < len(parts):\n",
    "                        kpt_x, kpt_y, kpt_vis = float(parts[i]), float(parts[i+1]), int(float(parts[i+2]))\n",
    "                        keypoints.append((kpt_x, kpt_y, kpt_vis))\n",
    "                        if kpt_vis > 0: num_visible_keypoints += 1\n",
    "                annotations.append({\n",
    "                    'class_id': class_id, 'class_name': FIELD_CLASS_NAMES[class_id],\n",
    "                    'x_center': x_c, 'y_center': y_c, 'width': w, 'height': h,\n",
    "                    'keypoints': keypoints, 'num_visible_keypoints': num_visible_keypoints\n",
    "                })\n",
    "    return annotations\n",
    "\n",
    "def add_field_label_info(df):\n",
    "    \"\"\"Add field label info to the dataframe.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['annotations'] = df['label_path'].apply(parse_field_label)\n",
    "    df['num_pitches'] = df['annotations'].apply(len)\n",
    "    df['avg_visible_keypoints'] = df['annotations'].apply(\n",
    "        lambda anns: np.mean([ann['num_visible_keypoints'] for ann in anns]) if anns else 0\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def augment_field_dataset(df, base_dir, split_name, prob=0.5, angles=[90, 180, 270]):\n",
    "    \"\"\"Apply rotation augmentation to the field dataset.\"\"\"\n",
    "    aug_images_dir = Path(base_dir) / split_name / 'images_augmented'\n",
    "    aug_labels_dir = Path(base_dir) / split_name / 'labels_augmented'\n",
    "    aug_images_dir.mkdir(exist_ok=True); aug_labels_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"Augmenting field {split_name} set...\")\n",
    "    aug_count = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if random.random() < prob:\n",
    "            angle = random.choice(angles)\n",
    "            rotated_img = rotate_image_90(row['image_path'], angle)\n",
    "            \n",
    "            base_filename = Path(row['filename']).stem\n",
    "            new_filename = f\"{base_filename}_rot{angle}.jpg\"\n",
    "            new_img_path = aug_images_dir / new_filename\n",
    "            new_label_path = aug_labels_dir / f\"{base_filename}_rot{angle}.txt\"\n",
    "            rotated_img.save(new_img_path)\n",
    "            \n",
    "            with open(new_label_path, 'w') as f:\n",
    "                for ann in row['annotations']:\n",
    "                    new_x, new_y, new_w, new_h = rotate_bbox_90(\n",
    "                        ann['x_center'], ann['y_center'], ann['width'], ann['height'], angle\n",
    "                    )\n",
    "                    \n",
    "                    label_line = f\"{ann['class_id']} {new_x} {new_y} {new_w} {new_h}\"\n",
    "                    for kpt_x, kpt_y, kpt_vis in ann['keypoints']:\n",
    "                        new_kpt_x, new_kpt_y = (rotate_keypoint_90(kpt_x, kpt_y, angle) if kpt_vis > 0 else (kpt_x, kpt_y))\n",
    "                        label_line += f\" {new_kpt_x} {new_kpt_y} {kpt_vis}\"\n",
    "                    f.write(label_line + \"\\n\")\n",
    "            aug_count += 1\n",
    "    print(f\"  Created {aug_count} augmented field samples for {split_name}.\")\n",
    "\n",
    "# --- Player Dataset (Detection) Functions ---\n",
    "PLAYER_CLASS_NAMES = ['ball', 'goalkeeper', 'player', 'referee']\n",
    "\n",
    "def parse_player_label(label_path):\n",
    "    \"\"\"Parse a YOLO format label file (detection).\"\"\"\n",
    "    if label_path is None or not Path(label_path).exists():\n",
    "        return []\n",
    "    annotations = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                class_id, x_c, y_c, w, h = int(parts[0]), float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
    "                annotations.append({\n",
    "                    'class_id': class_id, 'class_name': PLAYER_CLASS_NAMES[class_id],\n",
    "                    'x_center': x_c, 'y_center': y_c, 'width': w, 'height': h\n",
    "                })\n",
    "    return annotations\n",
    "\n",
    "def add_player_label_info(df):\n",
    "    \"\"\"Add player label info to the dataframe.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['annotations'] = df['label_path'].apply(parse_player_label)\n",
    "    df['num_objects'] = df['annotations'].apply(len)\n",
    "    for class_id, class_name in enumerate(PLAYER_CLASS_NAMES):\n",
    "        df[f'num_{class_name}s'] = df['annotations'].apply(\n",
    "            lambda anns: sum(1 for ann in anns if ann['class_id'] == class_id)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def augment_player_dataset(df, base_dir, split_name, prob=0.5, angles=[90, 180, 270]):\n",
    "    \"\"\"Apply rotation augmentation to the player dataset.\"\"\"\n",
    "    aug_images_dir = Path(base_dir) / split_name / 'images_augmented'\n",
    "    aug_labels_dir = Path(base_dir) / split_name / 'labels_augmented'\n",
    "    aug_images_dir.mkdir(exist_ok=True); aug_labels_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"Augmenting player {split_name} set...\")\n",
    "    aug_count = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if random.random() < prob:\n",
    "            angle = random.choice(angles)\n",
    "            rotated_img = rotate_image_90(row['image_path'], angle)\n",
    "            \n",
    "            base_filename = Path(row['filename']).stem\n",
    "            new_filename = f\"{base_filename}_rot{angle}.jpg\"\n",
    "            new_img_path = aug_images_dir / new_filename\n",
    "            new_label_path = aug_labels_dir / f\"{base_filename}_rot{angle}.txt\"\n",
    "            rotated_img.save(new_img_path)\n",
    "            \n",
    "            with open(new_label_path, 'w') as f:\n",
    "                for ann in row['annotations']:\n",
    "                    new_x, new_y, new_w, new_h = rotate_bbox_90(\n",
    "                        ann['x_center'], ann['y_center'], ann['width'], ann['height'], angle\n",
    "                    )\n",
    "                    f.write(f\"{ann['class_id']} {new_x} {new_y} {new_w} {new_h}\\n\")\n",
    "            aug_count += 1\n",
    "    print(f\"  Created {aug_count} augmented player samples for {split_name}.\")\n",
    "\n",
    "# ...existing code...\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def copy_originals_to_yolo(data_dir):\n",
    "    data_dir = Path(data_dir)\n",
    "    for split in ['train','valid','test']:\n",
    "        src_images = data_dir / split / 'images_orig'\n",
    "        src_labels = data_dir / split / 'labels_orig'\n",
    "        dst_images = data_dir / split / 'images'\n",
    "        dst_labels = data_dir / split / 'labels'\n",
    "        dst_images.mkdir(parents=True, exist_ok=True)\n",
    "        dst_labels.mkdir(parents=True, exist_ok=True)\n",
    "        if src_images.exists():\n",
    "            for f in src_images.glob('*.jpg'):\n",
    "                shutil.copy(f, dst_images)\n",
    "        if src_labels.exists():\n",
    "            for f in src_labels.glob('*.txt'):\n",
    "                shutil.copy(f, dst_labels)\n",
    "    print(f\"Copied originals for {data_dir}\")\n",
    "# ...existing code...\n",
    "# --- YAML Creation Function ---\n",
    "def create_dataset_yaml(data_dir, class_names, kpt_shape=None, use_augmentation=True):\n",
    "    \"\"\"Creates the data.yaml file for YOLO training.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # Create main directories if they don't exist\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        (data_dir / split).mkdir(parents=True, exist_ok=True)\n",
    "        (data_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (data_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Move original images/labels\n",
    "    # shutil.move(str(data_dir / 'train' / 'images'), str(data_dir / 'train' / 'images_orig'))\n",
    "    # shutil.move(str(data_dir / 'train' / 'labels'), str(data_dir / 'train' / 'labels_orig'))\n",
    "    # shutil.move(str(data_dir / 'valid' / 'images'), str(data_dir / 'valid' / 'images_orig'))\n",
    "    # shutil.move(str(data_dir / 'valid' / 'labels'), str(data_dir / 'valid' / 'labels_orig'))\n",
    "    # shutil.move(str(data_dir / 'test' / 'images'), str(data_dir / 'test' / 'images_orig'))\n",
    "    # shutil.move(str(data_dir / 'test' / 'labels'), str(data_dir / 'test' / 'labels_orig'))\n",
    "    \n",
    "    # # Rename augmented dirs to be the new train/valid/test dirs\n",
    "    # shutil.move(str(data_dir / 'train' / 'images_augmented'), str(data_dir / 'train' / 'images'))\n",
    "    # shutil.move(str(data_dir / 'train' / 'labels_augmented'), str(data_dir / 'train' / 'labels'))\n",
    "    # shutil.move(str(data_dir / 'valid' / 'images_augmented'), str(data_dir / 'valid' / 'images'))\n",
    "    # shutil.move(str(data_dir / 'valid' / 'labels_augmented'), str(data_dir / 'valid' / 'labels'))\n",
    "    # shutil.move(str(data_dir / 'test' / 'images_augmented'), str(data_dir / 'test' / 'images'))\n",
    "    # shutil.move(str(data_dir / 'test' / 'labels_augmented'), str(data_dir / 'test' / 'labels'))\n",
    "    \n",
    "    if use_augmentation:\n",
    "        for split in ['train', 'valid', 'test']:\n",
    "            aug_images = data_dir / split / 'images_augmented'\n",
    "            aug_labels = data_dir / split / 'labels_augmented'\n",
    "            if aug_images.exists():\n",
    "                for f in aug_images.glob('*.jpg'):\n",
    "                    shutil.copy(f, data_dir / split / 'images')\n",
    "            if aug_labels.exists():\n",
    "                for f in aug_labels.glob('*.txt'):\n",
    "                    shutil.copy(f, data_dir / split / 'labels')\n",
    "    \n",
    "    # Create data.yaml\n",
    "\n",
    "    train_abs_path = (data_dir / 'train' / 'images').absolute()\n",
    "    val_abs_path = (data_dir / 'valid' / 'images').absolute()\n",
    "    test_abs_path = (data_dir / 'test' / 'images').absolute()\n",
    "    \n",
    "    # Create data.yaml\n",
    "    yaml_content = f\"\"\"\n",
    "    train: {train_abs_path}\n",
    "    val: {val_abs_path}\n",
    "    test: {test_abs_path}\n",
    "\n",
    "    names: {class_names}\n",
    "    nc: {len(class_names)}\n",
    "    \"\"\"\n",
    "    \n",
    "    if kpt_shape:\n",
    "        yaml_content += f\"\\nkpt_shape: {kpt_shape}\\n\"\n",
    "        \n",
    "    yaml_path = data_dir / 'data.yaml'\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "        \n",
    "    print(f\"Created {yaml_path} with ABSOLUTE paths.\")\n",
    "    return str(yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 298 images from player_dataset/train/images_orig\n",
      "  Loaded 49 images from player_dataset/valid/images_orig\n",
      "  Loaded 25 images from player_dataset/test/images_orig\n",
      "Augmenting player train set...\n",
      "  Created 148 augmented player samples for train.\n",
      "Augmenting player valid set...\n",
      "  Created 10 augmented player samples for valid.\n",
      "Augmenting player test set...\n",
      "  Created 12 augmented player samples for test.\n",
      "Copied originals for player_dataset\n",
      "Created player_dataset/data.yaml with ABSOLUTE paths.\n",
      "  Loaded 255 images from field_dataset/train/images_orig\n",
      "  Loaded 34 images from field_dataset/valid/images_orig\n",
      "  Loaded 28 images from field_dataset/test/images_orig\n",
      "Augmenting field train set...\n",
      "  Created 129 augmented field samples for train.\n",
      "Augmenting field valid set...\n",
      "  Created 12 augmented field samples for valid.\n",
      "Augmenting field test set...\n",
      "  Created 9 augmented field samples for test.\n",
      "Copied originals for field_dataset\n",
      "Created field_dataset/data.yaml with ABSOLUTE paths.\n"
     ]
    }
   ],
   "source": [
    "# --- Process Player Dataset ---\n",
    "player_base_dir = 'player_dataset'\n",
    "player_train_df = load_dataset_split(player_base_dir, 'train')\n",
    "player_valid_df = load_dataset_split(player_base_dir, 'valid')\n",
    "player_test_df = load_dataset_split(player_base_dir, 'test')\n",
    "\n",
    "player_train_df = add_player_label_info(player_train_df)\n",
    "player_valid_df = add_player_label_info(player_valid_df)\n",
    "player_test_df = add_player_label_info(player_test_df)\n",
    "\n",
    "augment_player_dataset(player_train_df, player_base_dir, 'train', prob=0.5)\n",
    "augment_player_dataset(player_valid_df, player_base_dir, 'valid', prob=0.3)\n",
    "augment_player_dataset(player_test_df, player_base_dir, 'test', prob=0.3)\n",
    "\n",
    "copy_originals_to_yolo('player_dataset')\n",
    "player_yaml_path = create_dataset_yaml(player_base_dir, PLAYER_CLASS_NAMES)\n",
    "\n",
    "# --- Process Field Dataset ---\n",
    "field_base_dir = 'field_dataset'\n",
    "field_train_df = load_dataset_split(field_base_dir, 'train')\n",
    "field_valid_df = load_dataset_split(field_base_dir, 'valid')\n",
    "field_test_df = load_dataset_split(field_base_dir, 'test')\n",
    "\n",
    "field_train_df = add_field_label_info(field_train_df)\n",
    "field_valid_df = add_field_label_info(field_valid_df)\n",
    "field_test_df = add_field_label_info(field_test_df)\n",
    "\n",
    "augment_field_dataset(field_train_df, field_base_dir, 'train', prob=0.5)\n",
    "augment_field_dataset(field_valid_df, field_base_dir, 'valid', prob=0.3)\n",
    "augment_field_dataset(field_test_df, field_base_dir, 'test', prob=0.3)\n",
    "\n",
    "copy_originals_to_yolo('field_dataset')\n",
    "field_yaml_path = create_dataset_yaml(field_base_dir, FIELD_CLASS_NAMES, kpt_shape=[NUM_KEYPOINTS, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_dataset/train: images=821, labels=821, aug_images=365, aug_labels=365\n",
      "player_dataset/valid: images=102, labels=102, aug_images=40, aug_labels=40\n",
      "player_dataset/test: images=57, labels=57, aug_images=22, aug_labels=22\n",
      "Verification done.\n",
      "field_dataset/train: images=597, labels=597, aug_images=342, aug_labels=342\n",
      "field_dataset/valid: images=64, labels=64, aug_images=30, aug_labels=30\n",
      "field_dataset/test: images=55, labels=55, aug_images=27, aug_labels=27\n",
      "Verification done.\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from pathlib import Path\n",
    "\n",
    "def verify_dataset_for_training(data_dir):\n",
    "    data_dir = Path(data_dir)\n",
    "    for split in ['train','valid','test']:\n",
    "        imgs = list((data_dir / split / 'images').glob('*.jpg'))\n",
    "        lbls = list((data_dir / split / 'labels').glob('*.txt'))\n",
    "        aug_imgs = list((data_dir / split / 'images_augmented').glob('*.jpg')) if (data_dir / split / 'images_augmented').exists() else []\n",
    "        aug_lbls = list((data_dir / split / 'labels_augmented').glob('*.txt')) if (data_dir / split / 'labels_augmented').exists() else []\n",
    "        print(f\"{data_dir}/{split}: images={len(imgs)}, labels={len(lbls)}, aug_images={len(aug_imgs)}, aug_labels={len(aug_lbls)}\")\n",
    "        # Print sample mismatches\n",
    "        img_stems = {p.stem for p in imgs}\n",
    "        lbl_stems = {p.stem for p in lbls}\n",
    "        missing_labels = sorted(list(img_stems - lbl_stems))[:5]\n",
    "        if missing_labels:\n",
    "            print(f\"  WARNING: {len(missing_labels)} images missing labels (examples): {missing_labels}\")\n",
    "        missing_images = sorted(list(lbl_stems - img_stems))[:5]\n",
    "        if missing_images:\n",
    "            print(f\"  WARNING: {len(missing_images)} labels without images (examples): {missing_images}\")\n",
    "    print(\"Verification done.\")\n",
    "\n",
    "# Run verification for both datasets\n",
    "verify_dataset_for_training('player_dataset')\n",
    "verify_dataset_for_training('field_dataset')\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LIGHTWEIGHT Settings: Batch=4, Workers=0, Image Size=320\n",
      "\n",
      "--- Starting Player Detector Training (Lightweight Mode) ---\n",
      "New https://pypi.org/project/ultralytics/8.3.233 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.13.7 torch-2.9.1 CPU (Apple M4)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=player_dataset/data.yaml, epochs=10, time=None, patience=100, batch=4, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=0, project=Initial_Evaluation, name=player_detection_lightweight6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Initial_Evaluation/player_detection_lightweight6\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/adity/Downloads/CS_4644/FIFA_player_detection/player_dataset/train/labels... 821 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 821/821 [00:00<00:00, 2382.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/adity/Downloads/CS_4644/FIFA_player_detection/player_dataset/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/adity/Downloads/CS_4644/FIFA_player_detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/adity/Downloads/CS_4644/FIFA_player_detection/player_dataset/valid/labels... 102 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 2929.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/adity/Downloads/CS_4644/FIFA_player_detection/player_dataset/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to Initial_Evaluation/player_detection_lightweight6/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mInitial_Evaluation/player_detection_lightweight6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adity/Downloads/CS_4644/FIFA_player_detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "       1/10         0G      2.917      2.462     0.9083         22        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:05<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.627     0.0992     0.0946     0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      2.657       1.54     0.8506         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:04<00:00,  3.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.634      0.122      0.119     0.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      2.457      1.377     0.8324         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:01<00:00,  3.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.788      0.139      0.137     0.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G       2.44      1.326     0.8286         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:04<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.694      0.158      0.157     0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      2.372      1.273      0.823         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:03<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.696       0.17       0.16     0.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      2.283      1.228     0.8169         22        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:10<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.699      0.192      0.196     0.0648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      2.205      1.174     0.8124         15        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:06<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.625       0.21      0.222     0.0822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G      2.161      1.131      0.807         21        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:08<00:00,  2.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447       0.58      0.224      0.229     0.0836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      2.132      1.102     0.8105         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:10<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.585      0.235      0.237     0.0842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      2.096      1.086     0.8041         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:10<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.596      0.243      0.246     0.0894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.195 hours.\n",
      "Optimizer stripped from Initial_Evaluation/player_detection_lightweight6/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from Initial_Evaluation/player_detection_lightweight6/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating Initial_Evaluation/player_detection_lightweight6/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.13.7 torch-2.9.1 CPU (Apple M4)\n",
      "Model summary (fused): 168 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.594      0.243      0.246     0.0894\n",
      "                  ball         96         96          1          0          0          0\n",
      "            goalkeeper         80         81      0.475      0.112      0.178     0.0553\n",
      "                player        102       2029      0.648      0.631      0.629      0.228\n",
      "               referee        102        241      0.253      0.228      0.178     0.0741\n",
      "Speed: 0.1ms preprocess, 12.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mInitial_Evaluation/player_detection_lightweight6\u001b[0m\n",
      "Player Detector Training Complete.\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- Configuration for Maximum Stability ---\n",
    "# Lowest resource footprint settings for CPU training\n",
    "STABLE_BATCH_SIZE = 4 \n",
    "STABLE_WORKERS = 0  \n",
    "LIGHTWEIGHT_IMG_SIZE = 320 # <--- NEW: Use 320x320 pixels instead of 640x640\n",
    "\n",
    "print(f\"Using LIGHTWEIGHT Settings: Batch={STABLE_BATCH_SIZE}, Workers={STABLE_WORKERS}, Image Size={LIGHTWEIGHT_IMG_SIZE}\")\n",
    "\n",
    "print(\"\\n--- Starting Player Detector Training (Lightweight Mode) ---\")\n",
    "\n",
    "player_model = YOLO('yolov8n.pt') \n",
    "\n",
    "player_detector_results = player_model.train(\n",
    "    data=player_yaml_path,\n",
    "    epochs=10,            \n",
    "    imgsz=LIGHTWEIGHT_IMG_SIZE, # <--- CRITICAL CHANGE\n",
    "    project='Initial_Evaluation',\n",
    "    name='player_detection_lightweight',\n",
    "    batch=STABLE_BATCH_SIZE, \n",
    "    workers=STABLE_WORKERS   \n",
    ")\n",
    "print(\"Player Detector Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training random-init run: random_scratch_1764540565 ---\n",
      "New https://pypi.org/project/ultralytics/8.3.233 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.13.7 torch-2.9.1 CPU (Apple M4)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=player_dataset/data.yaml, epochs=10, time=None, patience=100, batch=4, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=0, project=initial_eval_compare, name=random_scratch_1764540565, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=initial_eval_compare/random_scratch_1764540565\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/adity/Downloads/CS_4644/FIFA_player_detection/player_dataset/train/labels.cache... 821 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 821/821 [00:00<?, ?it/s]\n",
      "/Users/adity/Downloads/CS_4644/FIFA_player_detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/adity/Downloads/CS_4644/FIFA_player_detection/player_dataset/valid/labels.cache... 102 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to initial_eval_compare/random_scratch_1764540565/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1minitial_eval_compare/random_scratch_1764540565\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adity/Downloads/CS_4644/FIFA_player_detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "       1/10         0G  0.0002544      6.439  0.0001426         22        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [01:22<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G    0.03799       4.68    0.01392         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [02:34<00:00,  1.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      3.212      5.204     0.9726         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [02:54<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447   0.000375    0.00357   0.000201   4.54e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      4.726      4.402      1.154         17        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [02:11<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447   0.000974     0.0134   0.000601   0.000124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      4.927      3.506      1.233         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [02:05<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447    0.00122     0.0184    0.00147   0.000444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      4.669       2.78      1.183         22        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [02:08<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.781     0.0154    0.00579    0.00109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      4.201      2.295       1.11         15        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [02:07<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.808     0.0355     0.0216    0.00432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G      3.766      2.043      1.046         21        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [02:01<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.844     0.0504     0.0381    0.00912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      3.449      1.875      1.015         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [02:07<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.856      0.059     0.0497     0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      3.306      1.799     0.9903         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [02:19<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:06<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447       0.86      0.058     0.0508     0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.382 hours.\n",
      "Optimizer stripped from initial_eval_compare/random_scratch_1764540565/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from initial_eval_compare/random_scratch_1764540565/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating initial_eval_compare/random_scratch_1764540565/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.13.7 torch-2.9.1 CPU (Apple M4)\n",
      "YOLOv8n summary (fused): 168 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:06<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447       0.86     0.0579     0.0508     0.0126\n",
      "Speed: 0.5ms preprocess, 38.7ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1minitial_eval_compare/random_scratch_1764540565\u001b[0m\n",
      "Using run directory: initial_eval_compare/random_scratch_1764540565\n",
      "Evaluating initial_eval_compare/random_scratch_1764540565/weights/best.pt ...\n",
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.13.7 torch-2.9.1 CPU (Apple M4)\n",
      "YOLOv8n summary (fused): 168 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/adity/Downloads/CS_4644/FIFA_player_detection/player_dataset/valid/labels.cache... 102 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<?, ?it/s]\n",
      "/Users/adity/Downloads/CS_4644/FIFA_player_detection/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:10<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        102       2447      0.859      0.058     0.0508     0.0127\n",
      "                  ball         96         96          1          0          0          0\n",
      "            goalkeeper         80         81          1          0          0          0\n",
      "                player        102       2029      0.437      0.232      0.197     0.0491\n",
      "               referee        102        241          1          0    0.00656    0.00152\n",
      "Speed: 0.5ms preprocess, 71.6ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/adity/Downloads/CS_4644/FIFA_player_detection/runs/detect/val\u001b[0m\n",
      "Done. Validation results printed above.\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "import time\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# keep seeds / config as before\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "EPOCHS = 10\n",
    "IMG_SZ = 320\n",
    "BATCH = 4\n",
    "WORKERS = 0\n",
    "\n",
    "def train_and_eval_random(run_name_prefix='random_scratch'):\n",
    "    run_name = f\"{run_name_prefix}_{int(time.time())}\"  # unique name avoids auto-increment confusion\n",
    "    print(f\"\\n--- Training random-init run: {run_name} ---\")\n",
    "    model = YOLO('yolov8n.yaml')  # <-- randomized initialization\n",
    "    model.train(\n",
    "        data=player_yaml_path,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMG_SZ,\n",
    "        batch=BATCH,\n",
    "        workers=WORKERS,\n",
    "        project='initial_eval_compare',\n",
    "        name=run_name,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    project_dir = Path('initial_eval_compare')\n",
    "    # find the latest directory that starts with the run name prefix\n",
    "    candidates = [d for d in project_dir.iterdir() if d.is_dir() and d.name.startswith(run_name_prefix)]\n",
    "    run_dir = sorted(candidates, key=lambda p: p.stat().st_mtime, reverse=True)[0]\n",
    "    print(f\"Using run directory: {run_dir}\")\n",
    "\n",
    "    best_path = run_dir / 'weights' / 'best.pt'\n",
    "    if not best_path.exists():\n",
    "        best_path = run_dir / 'weights' / 'last.pt'\n",
    "    if not best_path.exists():\n",
    "        raise FileNotFoundError(f\"No weights found in {run_dir}/weights\")\n",
    "\n",
    "    print(f\"Evaluating {best_path} ...\")\n",
    "    val_res = YOLO(str(best_path)).val(data=player_yaml_path)\n",
    "    print(\"Done. Validation results printed above.\")\n",
    "    return val_res\n",
    "\n",
    "# Run only the randomized-weights experiment\n",
    "res_scratch = train_and_eval_random('random_scratch')\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
